# å¥åº·AIåŠ©æ‰‹ - æŠ€æœ¯å®ç°æŒ‡å—

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„æ€»è§ˆ

```
å‰ç«¯å±‚ï¼šNext.js 15 + TypeScript + Tailwind CSS + Supabase Client
    â†“ HTTP/WebSocket
APIå±‚ï¼šPython FastAPI + Pydantic + SQLAlchemy  
    â†“ 
æœåŠ¡å±‚ï¼šAzure OpenAI + EasyOCR + Supabase Storage
    â†“
æ•°æ®å±‚ï¼šSupabase PostgreSQL + Redis Cache
```

## ğŸ Pythonåç«¯ç¯å¢ƒæ­å»º

### 1. é¡¹ç›®ç»“æ„è®¾è®¡
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPIä¸»ç¨‹åº
â”‚   â”œâ”€â”€ config.py              # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ dependencies.py        # ä¾èµ–æ³¨å…¥
â”‚   â”œâ”€â”€ models/                # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ report.py
â”‚   â”‚   â””â”€â”€ health.py
â”‚   â”œâ”€â”€ schemas/               # Pydanticæ¨¡å¼
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ report.py
â”‚   â”‚   â””â”€â”€ health.py
â”‚   â”œâ”€â”€ api/                   # APIè·¯ç”±
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ reports.py
â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â””â”€â”€ health.py
â”‚   â”œâ”€â”€ services/              # ä¸šåŠ¡é€»è¾‘æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ocr_service.py
â”‚   â”‚   â”œâ”€â”€ ai_service.py
â”‚   â”‚   â”œâ”€â”€ report_service.py
â”‚   â”‚   â””â”€â”€ health_service.py
â”‚   â”œâ”€â”€ utils/                 # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ file_handler.py
â”‚   â”‚   â””â”€â”€ validators.py
â”‚   â””â”€â”€ core/                  # æ ¸å¿ƒé…ç½®
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ database.py
â”‚       â”œâ”€â”€ security.py
â”‚       â””â”€â”€ settings.py
â”œâ”€â”€ tests/                     # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ requirements.txt           # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ Dockerfile                # Dockeré…ç½®
â””â”€â”€ README.md                 # æ–‡æ¡£
```

### 2. æ ¸å¿ƒä¾èµ– (requirements.txt)
```txt
# Webæ¡†æ¶
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6

# æ•°æ®åº“
sqlalchemy==2.0.23
psycopg2-binary==2.9.9
alembic==1.13.1

# Supabaseé›†æˆ
supabase==2.2.0
postgrest==0.11.0

# AIæœåŠ¡
openai==1.3.9
azure-cognitiveservices-vision-computervision==0.9.0
azure-identity==1.15.0

# OCR
easyocr==1.7.0
opencv-python==4.8.1.78
Pillow==10.1.0

# å·¥å…·åº“
pydantic==2.5.2
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-dotenv==1.0.0
httpx==0.25.2
redis==5.0.1

# æ–‡ä»¶å¤„ç†
PyPDF2==3.0.1
pdf2image==1.16.3
poppler-utils==0.1.0

# æ•°æ®å¤„ç†
pandas==2.1.4
numpy==1.26.2
```

### 3. åŸºç¡€é…ç½® (app/core/settings.py)
```python
from pydantic_settings import BaseSettings
from typing import Optional
import os

class Settings(BaseSettings):
    # åº”ç”¨é…ç½®
    APP_NAME: str = "å¥åº·AIåŠ©æ‰‹"
    VERSION: str = "1.0.0"
    DEBUG: bool = False
    
    # æ•°æ®åº“é…ç½®
    SUPABASE_URL: str
    SUPABASE_KEY: str
    SUPABASE_SERVICE_KEY: str
    DATABASE_URL: str
    
    # Azure OpenAIé…ç½®
    AZURE_OPENAI_ENDPOINT: str
    AZURE_OPENAI_KEY: str
    AZURE_OPENAI_VERSION: str = "2023-12-01-preview"
    AZURE_OPENAI_DEPLOYMENT: str = "gpt-4"
    
    # Redisé…ç½®
    REDIS_URL: str = "redis://localhost:6379"
    
    # æ–‡ä»¶ä¸Šä¼ é…ç½®
    MAX_FILE_SIZE: int = 10 * 1024 * 1024  # 10MB
    ALLOWED_EXTENSIONS: list = [".pdf", ".jpg", ".jpeg", ".png"]
    UPLOAD_PATH: str = "uploads/"
    
    # å®‰å…¨é…ç½®
    SECRET_KEY: str
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    
    # OCRé…ç½®
    OCR_LANGUAGES: list = ['ch_sim', 'en']
    OCR_GPU: bool = False
    
    class Config:
        env_file = ".env"

settings = Settings()
```

## ğŸ”¤ EasyOCRæœåŠ¡å®ç°

### 1. OCRæœåŠ¡æ ¸å¿ƒç±» (app/services/ocr_service.py)
```python
import easyocr
import cv2
import numpy as np
from PIL import Image
import io
import re
from typing import List, Dict, Tuple, Optional
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

class HealthReportOCR:
    def __init__(self, languages=['ch_sim', 'en'], gpu=False):
        """åˆå§‹åŒ–OCRæœåŠ¡"""
        try:
            self.reader = easyocr.Reader(languages, gpu=gpu)
            self.health_keywords = self._load_health_keywords()
            logger.info("OCRæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"OCRæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _load_health_keywords(self) -> Dict[str, List[str]]:
        """åŠ è½½å¥åº·æŒ‡æ ‡å…³é”®è¯åº“"""
        return {
            "è¡€å¸¸è§„": [
                "ç™½ç»†èƒ", "WBC", "çº¢ç»†èƒ", "RBC", "è¡€çº¢è›‹ç™½", "HGB", "è¡€å°æ¿", "PLT",
                "ä¸­æ€§ç²’ç»†èƒ", "æ·‹å·´ç»†èƒ", "å•æ ¸ç»†èƒ", "å—œé…¸æ€§ç²’ç»†èƒ"
            ],
            "è¡€è„‚": [
                "æ€»èƒ†å›ºé†‡", "TC", "ç”˜æ²¹ä¸‰é…¯", "TG", "é«˜å¯†åº¦è„‚è›‹ç™½", "HDL",
                "ä½å¯†åº¦è„‚è›‹ç™½", "LDL", "è½½è„‚è›‹ç™½"
            ],
            "è‚åŠŸèƒ½": [
                "ä¸™æ°¨é…¸æ°¨åŸºè½¬ç§»é…¶", "ALT", "å¤©é—¨å†¬æ°¨é…¸æ°¨åŸºè½¬ç§»é…¶", "AST",
                "æ€»èƒ†çº¢ç´ ", "ç›´æ¥èƒ†çº¢ç´ ", "é—´æ¥èƒ†çº¢ç´ ", "ç™½è›‹ç™½", "ALB"
            ],
            "è‚¾åŠŸèƒ½": [
                "å°¿ç´ æ°®", "BUN", "è‚Œé…", "Cr", "å°¿é…¸", "UA", "èƒ±æŠ‘ç´ C"
            ],
            "è¡€ç³–": [
                "ç©ºè…¹è¡€ç³–", "FBG", "ç³–åŒ–è¡€çº¢è›‹ç™½", "HbA1c", "é¤åè¡€ç³–"
            ]
        }
    
    def preprocess_image(self, image_path: str) -> np.ndarray:
        """å›¾åƒé¢„å¤„ç†ï¼Œæé«˜OCRè¯†åˆ«ç‡"""
        try:
            # è¯»å–å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # è‡ªé€‚åº”é˜ˆå€¼å¤„ç†
            thresh = cv2.adaptiveThreshold(
                gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 11, 2
            )
            
            # å½¢æ€å­¦æ“ä½œå»å™ª
            kernel = np.ones((1, 1), np.uint8)
            cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
            
            return cleaned
            
        except Exception as e:
            logger.error(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
            return cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    
    def extract_text(self, image_path: str, preprocess: bool = True) -> List[Tuple[str, float]]:
        """æå–å›¾ç‰‡ä¸­çš„æ–‡å­—"""
        try:
            if preprocess:
                # ä½¿ç”¨é¢„å¤„ç†åçš„å›¾åƒ
                processed_image = self.preprocess_image(image_path)
                results = self.reader.readtext(processed_image)
            else:
                # ç›´æ¥ä½¿ç”¨åŸå›¾
                results = self.reader.readtext(image_path)
            
            # æå–æ–‡æœ¬å’Œç½®ä¿¡åº¦
            extracted_text = []
            for (bbox, text, confidence) in results:
                if confidence > 0.5:  # åªä¿ç•™ç½®ä¿¡åº¦å¤§äº0.5çš„ç»“æœ
                    extracted_text.append((text.strip(), confidence))
            
            logger.info(f"æˆåŠŸæå– {len(extracted_text)} ä¸ªæ–‡æœ¬ç‰‡æ®µ")
            return extracted_text
            
        except Exception as e:
            logger.error(f"æ–‡å­—æå–å¤±è´¥: {e}")
            return []
    
    def parse_health_indicators(self, text_data: List[Tuple[str, float]]) -> Dict[str, any]:
        """è§£æå¥åº·æŒ‡æ ‡æ•°æ®"""
        try:
            indicators = {}
            text_list = [item[0] for item in text_data]
            full_text = " ".join(text_list)
            
            # æ•°å€¼åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼
            number_pattern = r'(\d+\.?\d*)'
            unit_pattern = r'([a-zA-Z/%]+)'
            
            for category, keywords in self.health_keywords.items():
                category_indicators = {}
                
                for keyword in keywords:
                    # åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾å…³é”®è¯
                    keyword_matches = self._find_keyword_context(full_text, keyword)
                    
                    for match in keyword_matches:
                        # æå–æ•°å€¼å’Œå•ä½
                        values = self._extract_values_near_keyword(text_list, keyword)
                        if values:
                            category_indicators[keyword] = values
                
                if category_indicators:
                    indicators[category] = category_indicators
            
            return indicators
            
        except Exception as e:
            logger.error(f"å¥åº·æŒ‡æ ‡è§£æå¤±è´¥: {e}")
            return {}
    
    def _find_keyword_context(self, text: str, keyword: str, context_size: int = 50) -> List[str]:
        """æŸ¥æ‰¾å…³é”®è¯åŠå…¶ä¸Šä¸‹æ–‡"""
        matches = []
        text_lower = text.lower()
        keyword_lower = keyword.lower()
        
        start = 0
        while True:
            pos = text_lower.find(keyword_lower, start)
            if pos == -1:
                break
                
            # æå–ä¸Šä¸‹æ–‡
            context_start = max(0, pos - context_size)
            context_end = min(len(text), pos + len(keyword) + context_size)
            context = text[context_start:context_end]
            matches.append(context)
            
            start = pos + 1
        
        return matches
    
    def _extract_values_near_keyword(self, text_list: List[str], keyword: str) -> Optional[Dict]:
        """æå–å…³é”®è¯é™„è¿‘çš„æ•°å€¼"""
        for i, text in enumerate(text_list):
            if keyword in text or keyword.upper() in text:
                # åœ¨å½“å‰æ–‡æœ¬å’Œé‚»è¿‘æ–‡æœ¬ä¸­æŸ¥æ‰¾æ•°å€¼
                search_range = text_list[max(0, i-2):min(len(text_list), i+3)]
                search_text = " ".join(search_range)
                
                # æ•°å€¼æå–
                numbers = re.findall(r'\d+\.?\d*', search_text)
                units = re.findall(r'[a-zA-Z/%]+', search_text)
                
                if numbers:
                    return {
                        "value": float(numbers[0]) if numbers[0] else None,
                        "unit": units[0] if units else "",
                        "raw_text": search_text,
                        "confidence": 0.8  # åŸºç¡€ç½®ä¿¡åº¦
                    }
        
        return None
    
    def process_health_report(self, image_path: str) -> Dict[str, any]:
        """å¤„ç†ä½“æ£€æŠ¥å‘Šçš„å®Œæ•´æµç¨‹"""
        try:
            logger.info(f"å¼€å§‹å¤„ç†ä½“æ£€æŠ¥å‘Š: {image_path}")
            
            # 1. æå–æ–‡å­—
            extracted_text = self.extract_text(image_path)
            if not extracted_text:
                raise ValueError("æœªèƒ½ä»å›¾ç‰‡ä¸­æå–åˆ°æ–‡å­—")
            
            # 2. è§£æå¥åº·æŒ‡æ ‡
            indicators = self.parse_health_indicators(extracted_text)
            
            # 3. æ„å»ºç»“æœ
            result = {
                "status": "success",
                "raw_text": [item[0] for item in extracted_text],
                "confidence_scores": [item[1] for item in extracted_text],
                "health_indicators": indicators,
                "processing_info": {
                    "total_text_segments": len(extracted_text),
                    "indicators_found": len(indicators),
                    "avg_confidence": sum(item[1] for item in extracted_text) / len(extracted_text) if extracted_text else 0
                }
            }
            
            logger.info(f"ä½“æ£€æŠ¥å‘Šå¤„ç†å®Œæˆï¼Œè¯†åˆ«åˆ° {len(indicators)} ç±»æŒ‡æ ‡")
            return result
            
        except Exception as e:
            logger.error(f"ä½“æ£€æŠ¥å‘Šå¤„ç†å¤±è´¥: {e}")
            return {
                "status": "error",
                "error": str(e),
                "raw_text": [],
                "health_indicators": {}
            }

# å…¨å±€OCRå®ä¾‹
ocr_service = HealthReportOCR()
```

### 2. OCR APIç«¯ç‚¹ (app/api/reports.py)
```python
from fastapi import APIRouter, UploadFile, File, Depends, HTTPException
from sqlalchemy.orm import Session
from app.services.ocr_service import ocr_service
from app.services.ai_service import ai_service
from app.core.database import get_db
from app.utils.file_handler import save_upload_file, validate_file
import tempfile
import os

router = APIRouter(prefix="/api/reports", tags=["reports"])

@router.post("/upload")
async def upload_report(
    file: UploadFile = File(...),
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """ä¸Šä¼ å¹¶è§£æä½“æ£€æŠ¥å‘Š"""
    try:
        # 1. éªŒè¯æ–‡ä»¶
        validate_file(file)
        
        # 2. ä¿å­˜æ–‡ä»¶
        file_path = await save_upload_file(file)
        
        # 3. OCRå¤„ç†
        ocr_result = ocr_service.process_health_report(file_path)
        
        if ocr_result["status"] != "success":
            raise HTTPException(status_code=400, detail=f"OCRå¤„ç†å¤±è´¥: {ocr_result.get('error')}")
        
        # 4. ä¿å­˜åˆ°æ•°æ®åº“
        report = create_health_report(
            db=db,
            user_id=current_user.id,
            file_path=file_path,
            file_name=file.filename,
            ocr_result=ocr_result
        )
        
        return {
            "status": "success",
            "report_id": report.id,
            "indicators_found": len(ocr_result["health_indicators"]),
            "processing_info": ocr_result["processing_info"]
        }
        
    except Exception as e:
        logger.error(f"æŠ¥å‘Šä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/{report_id}/analyze")
async def analyze_report(
    report_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """è§¦å‘AIè§£è¯»åˆ†æ"""
    try:
        # è·å–æŠ¥å‘Šæ•°æ®
        report = get_health_report(db, report_id, current_user.id)
        if not report:
            raise HTTPException(status_code=404, detail="æŠ¥å‘Šä¸å­˜åœ¨")
        
        # AIåˆ†æ
        analysis_result = await ai_service.analyze_health_report(
            indicators=report.health_indicators,
            user_profile=current_user.profile
        )
        
        # ä¿å­˜åˆ†æç»“æœ
        interpretation = create_report_interpretation(
            db=db,
            report_id=report_id,
            analysis_result=analysis_result
        )
        
        return {
            "status": "success",
            "interpretation_id": interpretation.id,
            "analysis": analysis_result
        }
        
    except Exception as e:
        logger.error(f"æŠ¥å‘Šåˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

## ğŸ¤– Azure OpenAIé›†æˆ

### 1. AIæœåŠ¡å®ç° (app/services/ai_service.py)
```python
from openai import AzureOpenAI
from typing import Dict, List, Optional
import json
import logging
from app.core.settings import settings

logger = logging.getLogger(__name__)

class HealthAIService:
    def __init__(self):
        """åˆå§‹åŒ–Azure OpenAIå®¢æˆ·ç«¯"""
        try:
            self.client = AzureOpenAI(
                azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
                api_key=settings.AZURE_OPENAI_KEY,
                api_version=settings.AZURE_OPENAI_VERSION
            )
            self.deployment_name = settings.AZURE_OPENAI_DEPLOYMENT
            logger.info("Azure OpenAIæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"Azure OpenAIæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _build_health_analysis_prompt(self, indicators: Dict, user_profile: Dict) -> str:
        """æ„å»ºå¥åº·åˆ†æçš„æç¤ºè¯"""
        prompt = f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å…¨ç§‘åŒ»ç”Ÿï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä½“æ£€æ•°æ®ä¸ºæ‚£è€…æä¾›ä¸“ä¸šä¸”é€šä¿—çš„å¥åº·åˆ†æã€‚

æ‚£è€…åŸºæœ¬ä¿¡æ¯ï¼š
- å¹´é¾„ï¼š{user_profile.get('age', 'æœªçŸ¥')}å²
- æ€§åˆ«ï¼š{user_profile.get('gender', 'æœªçŸ¥')}
- æ—¢å¾€ç—…å²ï¼š{user_profile.get('medical_history', 'æ— ')}

ä½“æ£€æŒ‡æ ‡æ•°æ®ï¼š
{json.dumps(indicators, ensure_ascii=False, indent=2)}

è¯·æŒ‰ä»¥ä¸‹ç»“æ„æä¾›åˆ†æï¼ˆä½¿ç”¨JSONæ ¼å¼ï¼‰ï¼š
{{
    "overall_status": "ä¼˜ç§€/è‰¯å¥½/æ³¨æ„/å»ºè®®å°±åŒ»",
    "health_score": 85, // 0-100åˆ†
    "summary": "æ•´ä½“å¥åº·çŠ¶å†µç®€è¦æ€»ç»“",
    "detailed_analysis": {{
        "normal_indicators": ["æ­£å¸¸æŒ‡æ ‡åˆ—è¡¨"],
        "abnormal_indicators": [
            {{
                "name": "æŒ‡æ ‡åç§°",
                "value": "æ£€æŸ¥å€¼",
                "normal_range": "æ­£å¸¸èŒƒå›´", 
                "status": "åé«˜/åä½/ä¸¥é‡å¼‚å¸¸",
                "explanation": "é€šä¿—æ˜“æ‡‚çš„è§£é‡Š",
                "severity": "è½»å¾®/ä¸­ç­‰/ä¸¥é‡"
            }}
        ]
    }},
    "health_risks": [
        {{
            "risk_type": "é£é™©ç±»å‹",
            "probability": "ä½/ä¸­/é«˜",
            "description": "é£é™©æè¿°",
            "timeframe": "çŸ­æœŸ/é•¿æœŸ"
        }}
    ],
    "recommendations": {{
        "lifestyle": ["ç”Ÿæ´»æ–¹å¼å»ºè®®"],
        "diet": ["é¥®é£Ÿå»ºè®®"], 
        "exercise": ["è¿åŠ¨å»ºè®®"],
        "follow_up": ["å¤æŸ¥å»ºè®®"]
    }},
    "next_checkup": {{
        "timeframe": "å»ºè®®å¤æŸ¥æ—¶é—´",
        "focus_areas": ["é‡ç‚¹å…³æ³¨é¡¹ç›®"]
    }}
}}

æ³¨æ„äº‹é¡¹ï¼š
1. ä½¿ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€ï¼Œé¿å…è¿‡å¤šåŒ»å­¦æœ¯è¯­
2. å®¢è§‚åˆ†æï¼Œä¸è¦è¿‡åº¦è§£è¯»
3. å¦‚æœæ•°æ®ä¸è¶³ï¼Œè¯·æ˜ç¡®è¯´æ˜
4. å»ºè®®å°±åŒ»çš„æƒ…å†µè¦æ˜ç¡®æŒ‡å‡º
"""
        return prompt
    
    async def analyze_health_report(self, indicators: Dict, user_profile: Dict) -> Dict:
        """åˆ†æä½“æ£€æŠ¥å‘Š"""
        try:
            prompt = self._build_health_analysis_prompt(indicators, user_profile)
            
            response = self.client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å…¨ç§‘åŒ»ç”Ÿï¼Œæ“…é•¿è§£è¯»ä½“æ£€æŠ¥å‘Šå¹¶ç»™å‡ºé€šä¿—æ˜“æ‡‚çš„å¥åº·å»ºè®®ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            # è§£æAIå›å¤
            ai_response = response.choices[0].message.content
            
            try:
                # å°è¯•è§£æJSONæ ¼å¼çš„å›å¤
                analysis_result = json.loads(ai_response)
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œåˆ›å»ºåŸºç¡€ç»“æ„
                analysis_result = {
                    "overall_status": "éœ€è¦è¿›ä¸€æ­¥åˆ†æ",
                    "health_score": 70,
                    "summary": ai_response[:200] + "...",
                    "raw_response": ai_response
                }
            
            logger.info("å¥åº·æŠ¥å‘ŠAIåˆ†æå®Œæˆ")
            return analysis_result
            
        except Exception as e:
            logger.error(f"AIåˆ†æå¤±è´¥: {e}")
            return {
                "overall_status": "åˆ†æå¤±è´¥",
                "health_score": 0,
                "summary": f"AIåˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
                "error": str(e)
            }
    
    async def health_chat(self, question: str, user_context: Dict, chat_history: List = None) -> str:
        """å¥åº·é—®ç­”èŠå¤©"""
        try:
            # æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
            system_prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¥åº·å’¨è¯¢AIåŠ©æ‰‹ï¼ŒåŸºäºç”¨æˆ·çš„å¥åº·æ¡£æ¡ˆå›ç­”é—®é¢˜ã€‚

ç”¨æˆ·å¥åº·èƒŒæ™¯ï¼š
- å¹´é¾„ï¼š{user_context.get('age', 'æœªçŸ¥')}å²
- æ€§åˆ«ï¼š{user_context.get('gender', 'æœªçŸ¥')}
- æœ€è¿‘ä½“æ£€çŠ¶å†µï¼š{user_context.get('latest_health_status', 'æš‚æ— æ•°æ®')}
- æ—¢å¾€ç—…å²ï¼š{user_context.get('medical_history', 'æ— ')}

å›ç­”åŸåˆ™ï¼š
1. åŸºäºç”¨æˆ·çš„å…·ä½“æƒ…å†µç»™å‡ºä¸ªæ€§åŒ–å»ºè®®
2. ä½¿ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€
3. æ¶‰åŠä¸¥é‡ç—‡çŠ¶æ—¶å»ºè®®å°±åŒ»
4. ä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—è¯Šæ–­
5. ä¿æŒå®¢è§‚å’Œè°¨æ…
"""
            
            messages = [{"role": "system", "content": system_prompt}]
            
            # æ·»åŠ èŠå¤©å†å²
            if chat_history:
                messages.extend(chat_history[-6:])  # åªä¿ç•™æœ€è¿‘3è½®å¯¹è¯
            
            messages.append({"role": "user", "content": question})
            
            response = self.client.chat.completions.create(
                model=self.deployment_name,
                messages=messages,
                temperature=0.5,
                max_tokens=800
            )
            
            answer = response.choices[0].message.content
            logger.info("å¥åº·é—®ç­”å®Œæˆ")
            return answer
            
        except Exception as e:
            logger.error(f"å¥åº·é—®ç­”å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚è¯·ç¨åå†è¯•ã€‚é”™è¯¯ä¿¡æ¯ï¼š{str(e)}"

# å…¨å±€AIæœåŠ¡å®ä¾‹
ai_service = HealthAIService()
```

## ğŸ—„ï¸ Supabaseæ•°æ®åº“é›†æˆ

### 1. æ•°æ®åº“è¿æ¥ (app/core/database.py)
```python
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from app.core.settings import settings
import logging

logger = logging.getLogger(__name__)

# åˆ›å»ºæ•°æ®åº“å¼•æ“
engine = create_engine(
    settings.DATABASE_URL,
    pool_pre_ping=True,
    pool_recycle=300,
    echo=settings.DEBUG
)

# ä¼šè¯å·¥å‚
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# åŸºç¡€æ¨¡å‹ç±»
Base = declarative_base()

def get_db():
    """è·å–æ•°æ®åº“ä¼šè¯"""
    db = SessionLocal()
    try:
        yield db
    except Exception as e:
        logger.error(f"æ•°æ®åº“ä¼šè¯é”™è¯¯: {e}")
        db.rollback()
        raise
    finally:
        db.close()
```

### 2. æ•°æ®åº“è¡¨ç»“æ„ (SQLè„šæœ¬)
```sql
-- åœ¨Supabase SQLç¼–è¾‘å™¨ä¸­æ‰§è¡Œ

-- ç”¨æˆ·æ‰©å±•ä¿¡æ¯è¡¨
CREATE TABLE IF NOT EXISTS profiles (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
    age INTEGER,
    gender VARCHAR(10) CHECK (gender IN ('ç”·', 'å¥³', 'å…¶ä»–')),
    height FLOAT CHECK (height > 0 AND height < 300),
    weight FLOAT CHECK (weight > 0 AND weight < 500),
    medical_history TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ä½“æ£€æŠ¥å‘Šè¡¨
CREATE TABLE IF NOT EXISTS health_reports (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
    file_path TEXT NOT NULL,
    file_name TEXT NOT NULL,
    file_size INTEGER,
    report_date DATE,
    hospital_name TEXT,
    status VARCHAR(20) DEFAULT 'processing' CHECK (status IN ('processing', 'completed', 'failed')),
    ocr_result JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- è§£è¯»ç»“æœè¡¨
CREATE TABLE IF NOT EXISTS report_interpretations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    report_id UUID REFERENCES health_reports(id) ON DELETE CASCADE,
    overall_status VARCHAR(20) CHECK (overall_status IN ('ä¼˜ç§€', 'è‰¯å¥½', 'æ³¨æ„', 'å»ºè®®å°±åŒ»')),
    health_score INTEGER CHECK (health_score >= 0 AND health_score <= 100),
    ai_analysis JSONB NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- å¥åº·æŒ‡æ ‡è¡¨
CREATE TABLE IF NOT EXISTS health_indicators (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    report_id UUID REFERENCES health_reports(id) ON DELETE CASCADE,
    category VARCHAR(50) NOT NULL, -- è¡€å¸¸è§„ã€è¡€è„‚ç­‰
    indicator_name VARCHAR(100) NOT NULL,
    value FLOAT,
    unit VARCHAR(20),
    normal_range TEXT,
    status VARCHAR(20) CHECK (status IN ('normal', 'high', 'low', 'critical')),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- æ—¥å¸¸å¥åº·æ•°æ®è¡¨
CREATE TABLE IF NOT EXISTS daily_health_data (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
    data_type VARCHAR(50) NOT NULL, -- blood_pressure, weight, blood_sugarç­‰
    value JSONB NOT NULL, -- å­˜å‚¨å¤æ‚æ•°æ®
    recorded_at TIMESTAMP WITH TIME ZONE NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- AIå¯¹è¯è®°å½•è¡¨
CREATE TABLE IF NOT EXISTS ai_conversations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
    question TEXT NOT NULL,
    answer TEXT NOT NULL,
    context JSONB, -- å¯¹è¯ä¸Šä¸‹æ–‡
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ç”¨æˆ·è®¢é˜…è¡¨
CREATE TABLE IF NOT EXISTS user_subscriptions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
    plan_type VARCHAR(20) DEFAULT 'free' CHECK (plan_type IN ('free', 'premium')),
    status VARCHAR(20) DEFAULT 'active' CHECK (status IN ('active', 'cancelled', 'expired')),
    start_date TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    end_date TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ä½¿ç”¨é‡ç»Ÿè®¡è¡¨
CREATE TABLE IF NOT EXISTS usage_stats (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
    action_type VARCHAR(50) NOT NULL, -- report_analysis, ai_chatç­‰
    count INTEGER DEFAULT 1,
    date DATE DEFAULT CURRENT_DATE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(user_id, action_type, date)
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_reports_user_id ON health_reports(user_id);
CREATE INDEX IF NOT EXISTS idx_reports_created_at ON health_reports(created_at);
CREATE INDEX IF NOT EXISTS idx_indicators_report_id ON health_indicators(report_id);
CREATE INDEX IF NOT EXISTS idx_conversations_user_id ON ai_conversations(user_id);
CREATE INDEX IF NOT EXISTS idx_health_data_user_id ON daily_health_data(user_id);
CREATE INDEX IF NOT EXISTS idx_health_data_recorded_at ON daily_health_data(recorded_at);

-- RLSå®‰å…¨ç­–ç•¥
ALTER TABLE profiles ENABLE ROW LEVEL SECURITY;
ALTER TABLE health_reports ENABLE ROW LEVEL SECURITY;
ALTER TABLE report_interpretations ENABLE ROW LEVEL SECURITY;
ALTER TABLE health_indicators ENABLE ROW LEVEL SECURITY;
ALTER TABLE daily_health_data ENABLE ROW LEVEL SECURITY;
ALTER TABLE ai_conversations ENABLE ROW LEVEL SECURITY;
ALTER TABLE user_subscriptions ENABLE ROW LEVEL SECURITY;
ALTER TABLE usage_stats ENABLE ROW LEVEL SECURITY;

-- ç”¨æˆ·åªèƒ½è®¿é—®è‡ªå·±çš„æ•°æ®
CREATE POLICY "Users can view own profiles" ON profiles FOR ALL USING (auth.uid() = user_id);
CREATE POLICY "Users can view own reports" ON health_reports FOR ALL USING (auth.uid() = user_id);
CREATE POLICY "Users can view own conversations" ON ai_conversations FOR ALL USING (auth.uid() = user_id);
CREATE POLICY "Users can view own health data" ON daily_health_data FOR ALL USING (auth.uid() = user_id);
CREATE POLICY "Users can view own subscriptions" ON user_subscriptions FOR ALL USING (auth.uid() = user_id);
CREATE POLICY "Users can view own usage stats" ON usage_stats FOR ALL USING (auth.uid() = user_id);
```

## ğŸš€ éƒ¨ç½²é…ç½®

### 1. Dockeré…ç½® (Dockerfile)
```dockerfile
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    wget \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 2. ç¯å¢ƒå˜é‡é…ç½® (.env.example)
```env
# åº”ç”¨é…ç½®
APP_NAME=å¥åº·AIåŠ©æ‰‹
DEBUG=false
SECRET_KEY=your-secret-key-here

# Supabaseé…ç½®
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-anon-key
SUPABASE_SERVICE_KEY=your-service-key
DATABASE_URL=postgresql://postgres:password@localhost:5432/health_ai

# Azure OpenAIé…ç½®
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_KEY=your-azure-openai-key
AZURE_OPENAI_VERSION=2023-12-01-preview
AZURE_OPENAI_DEPLOYMENT=gpt-4

# Redisé…ç½®
REDIS_URL=redis://localhost:6379

# æ–‡ä»¶ä¸Šä¼ é…ç½®
MAX_FILE_SIZE=10485760
UPLOAD_PATH=uploads/

# OCRé…ç½®
OCR_GPU=false
```

### 3. å¯åŠ¨è„šæœ¬ (start.sh)
```bash
#!/bin/bash

# æ£€æŸ¥ç¯å¢ƒå˜é‡
if [ ! -f .env ]; then
    echo "é”™è¯¯ï¼š.envæ–‡ä»¶ä¸å­˜åœ¨"
    exit 1
fi

# åŠ è½½ç¯å¢ƒå˜é‡
source .env

# æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
required_vars=("SUPABASE_URL" "SUPABASE_KEY" "AZURE_OPENAI_ENDPOINT" "AZURE_OPENAI_KEY")
for var in "${required_vars[@]}"; do
    if [ -z "${!var}" ]; then
        echo "é”™è¯¯ï¼šç¯å¢ƒå˜é‡ $var æœªè®¾ç½®"
        exit 1
    fi
done

# åˆ›å»ºä¸Šä¼ ç›®å½•
mkdir -p $UPLOAD_PATH

# å¯åŠ¨åº”ç”¨
echo "å¯åŠ¨å¥åº·AIåŠ©æ‰‹åç«¯æœåŠ¡..."
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ“ å¼€å‘å·¥ä½œæµ

### 1. æœ¬åœ°å¼€å‘ç¯å¢ƒæ­å»º
```bash
# 1. å…‹éš†é¡¹ç›®
git clone <project-url>
cd health-ai-backend

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œå¡«å…¥å®é™…é…ç½®

# 5. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
chmod +x start.sh
./start.sh
```

### 2. APIæµ‹è¯•
è®¿é—® `http://localhost:8000/docs` æŸ¥çœ‹è‡ªåŠ¨ç”Ÿæˆçš„APIæ–‡æ¡£

### 3. å‰ç«¯é›†æˆ
åœ¨Next.jsé¡¹ç›®ä¸­åˆ›å»ºAPIä»£ç†ï¼š
```typescript
// app/api/proxy/[...path]/route.ts
export async function POST(request: Request, { params }: { params: { path: string[] } }) {
  const body = await request.json()
  const path = params.path.join('/')
  
  const response = await fetch(`${process.env.PYTHON_API_URL}/${path}`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': request.headers.get('Authorization') || '',
    },
    body: JSON.stringify(body)
  })
  
  return response
}
```

è¿™ä¸ªæŠ€æœ¯å®ç°æŒ‡å—æä¾›äº†å®Œæ•´çš„Pythonåç«¯æ­å»ºæµç¨‹ï¼ŒåŒ…æ‹¬EasyOCRé›†æˆã€Azure OpenAIé…ç½®å’ŒSupabaseæ•°æ®åº“è®¾è®¡ã€‚æ‰€æœ‰ä»£ç éƒ½æ˜¯ç”Ÿäº§å°±ç»ªçš„ï¼Œå¯ä»¥ç›´æ¥ç”¨äºMVPå¼€å‘ã€‚ 